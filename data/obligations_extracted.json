[
  {
    "id": "obl-ai-literacy",
    "article": "Article 4",
    "description": "AI Literacy obligations - You must take measures to ensure a sufficient level of AI literacy for your staff (and other people dealing with the operation and use of AI systems on your behalf), taking into account their technical knowledge, experience, education and training and the context the AI systems are to be used in.",
    "applicableRoles": [
      "Provider",
      "Deployer",
      "Distributor",
      "Importer",
      "AuthorizedRepresentative",
      "ProductManufacturer"
    ],
    "riskCategory": [
      "Minimal",
      "Limited",
      "High",
      "Prohibited"
    ],
    "isGPAIApplicable": true,
    "hasSystemicRiskApplicable": true
  },
  {
    "id": "obl-transparency-interaction",
    "article": "Article 50",
    "description": "Transparency obligations: Interacting directly with users - Ensure that AI systems intended to interact directly with people are designed and developed so that users are informed that they are interacting with an AI system. This does not apply to uses permitted by law to detect, prevent or investigate criminal offences.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "Limited"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-transparency-synthetic",
    "article": "Article 50",
    "description": "Transparency obligations: Synthetic content - Ensure that the outputs of the AI system are marked in a machine-readable format and detectable as artificially generated or manipulated. Ensure that technical solutions are effective, interoperable, robust and reliable as far as this is technically feasible. This does not apply to uses permitted by law to detect, prevent or investigate criminal offences.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "Limited"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-transparency-emotion",
    "article": "Article 50",
    "description": "Transparency obligations: Emotion & biometric - Obtain user consent before processing biometric and other personal data, unless authorised by law for criminal offences. This does not apply to uses permitted by law to detect, prevent or investigate criminal offences.",
    "applicableRoles": [
      "Deployer"
    ],
    "riskCategory": [
      "Limited"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-transparency-deepfake",
    "article": "Article 50",
    "description": "Transparency obligations: Deep fakes & text for informing the public - Disclose that the content has been artificially generated or manipulated. This does not apply to uses permitted by law to detect, prevent or investigate criminal offences.",
    "applicableRoles": [
      "Deployer"
    ],
    "riskCategory": [
      "Limited"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-provider-high-risk",
    "article": "Article 16",
    "description": "Provider obligations for high-risk AI systems - As a provider of a high-risk AI system, you must comply with Article 16 obligations including: ensuring your system meets all requirements before placement, implementing quality management system, maintaining technical documentation, keeping system logs, completing conformity assessment, drawing up EU declaration of conformity, affixing CE marking, complying with registration obligations, taking corrective actions, and ensuring accessibility requirements.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-deployer-high-risk",
    "article": "Article 26",
    "description": "Deployer obligations for high-risk AI systems - As a deployer of a high-risk AI system, you must comply with Article 26 obligations including: taking appropriate technical and organisational measures, assigning competent trained individuals for human oversight, monitoring system performance, ensuring relevant input data, keeping system logs for at least six months, maintaining cybersecurity measures, suspending use if risks are detected, informing individuals of AI-assisted decisions, consulting workers' representatives, and cooperating with competent authorities.",
    "applicableRoles": [
      "Deployer"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-distributor-high-risk",
    "article": "Article 24",
    "description": "Distributor obligations for high-risk AI systems - As a distributor of a high-risk AI system, you must comply with Article 24 obligations including: verifying CE conformity marking and documentation before distribution, not distributing non-compliant systems, ensuring proper storage and transport conditions, taking corrective actions for non-compliant systems, providing information to authorities upon request, and cooperating with national competent authorities.",
    "applicableRoles": [
      "Distributor"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-importer-high-risk",
    "article": "Article 23",
    "description": "Importer obligations for high-risk AI systems - As an importer of a high-risk AI system, you must comply with Article 23 obligations including: verifying provider has completed conformity assessment and prepared documentation, not placing non-conforming systems on market, indicating business name and address, ensuring proper storage conditions, keeping key documents for 10 years, providing information to authorities upon request, and cooperating with authorities.",
    "applicableRoles": [
      "Importer"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-authorized-rep",
    "article": "Article 22",
    "description": "Authorised representative obligations - As an authorised representative, appointed via a written mandate by a provider of a high-risk AI system or a General Purpose AI model, you must comply with Article 22 and/or Article 54 obligations including: being based in the EU, performing mandated tasks, providing copy of mandate to authorities upon request, being mandated to communicate with authorities on compliance issues, and terminating mandate if provider acts contrary to obligations.",
    "applicableRoles": [
      "AuthorizedRepresentative"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": true,
    "hasSystemicRiskApplicable": true
  },
  {
    "id": "obl-product-manufacturer",
    "article": "Recital 47 & 166",
    "description": "Product manufacturer obligations - As a product manufacturer placing on the market / putting into service an AI system under your name or trademark (regardless of whether or not you are based in the EU, or that system is high-risk), you must comply with Recital 47 and Recital 166 obligations. If your system is high-risk, you are also considered a 'provider' of that AI system according to Article 25.",
    "applicableRoles": [
      "ProductManufacturer"
    ],
    "riskCategory": [
      "Minimal",
      "Limited",
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-gpai-provider",
    "article": "Article 53",
    "description": "General Purpose AI model obligations - You need to follow these obligations for Providers of General Purpose AI (GPAI) models under Article 53. In summary, you must: Create and keep technical documentation for the AI model, and make it available to the AI Office upon request; Create and keep documentation for providers integrating AI models, balancing transparency and protection of IP; Put in place a policy to respect Union copyright law; Publish a publicly available summary of AI model training data according to a template provided by the AI Office.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "Minimal",
      "Limited",
      "High"
    ],
    "isGPAIApplicable": true,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-gpai-systemic-risk",
    "article": "Article 55",
    "description": "General Purpose AI model with systemic risk obligations - You need to follow these obligations for Providers of General Purpose AI (GPAI) models with Systemic Risk under Article 55. In summary, you must: Conduct model evaluations and adversarial testing with the aim of identifying and mitigating systemic risks; Assess and mitigate possible systemic risks at the EU level caused by the development, deployment, or use of general-purpose AI models with systemic risk; Track and report serious incidents to the AI Office and National Competent Authorities; Ensure adequate cybersecurity protections for the model and its physical infrastructure.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "Minimal",
      "Limited",
      "High"
    ],
    "isGPAIApplicable": true,
    "hasSystemicRiskApplicable": true
  },
  {
    "id": "obl-registration",
    "article": "Article 49",
    "description": "Registration in EU database - Providers must register their high-risk AI systems in the EU database before placement on market or putting into service. Public authorities must ensure the system is registered and must not use unregistered systems. Providers must also document their assessment and provide this documentation to the National Competent Authorities (NCA) upon request.",
    "applicableRoles": [
      "Provider",
      "Deployer"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-fundamental-rights",
    "article": "Article 27",
    "description": "Fundamental rights impacts assessment - Prior to deploying a high-risk system, you must perform a fundamental rights impacts assessment (unless the system is intended to be used in critical infrastructure). This assessment helps identify and mitigate potential impacts on fundamental rights and freedoms.",
    "applicableRoles": [
      "Deployer"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-handover",
    "article": "Article 25",
    "description": "Handover obligations - If a deployer, distributor, or importer makes a 'substantial modification' to your AI system, they will be considered a 'provider' of that system under Article 25. However, you (the original provider) will have obligations to provide the new provider with: Technical documentation; Information about the capabilities of the AI system; Technical access; Assistance to help the new provider fulfil their obligations under the Act.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-nsa-notification",
    "article": "Article 49",
    "description": "NSA Notification required - If a provider considers their AI system to not pose a significant risk, they must register their system in the EU database before placement. They must also document their assessment and provide this documentation to the National Competent Authorities (NCA) upon request. If a market surveillance authority finds that the AI system has been misclassified, your system would be subject to the 'high-risk' obligations and you may be subject to fines under Article 99.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "High"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-excluded-open-source",
    "article": "Article 2",
    "description": "Excluded: Open source systems - Until your AI system is placed on the market or put into service by a provider as part of an AI system that is high-risk, prohibited, general purpose, or has transparency obligations, your open source system is likely excluded from the EU AI Act, which means it is not subject to any obligations.",
    "applicableRoles": [
      "Provider"
    ],
    "riskCategory": [
      "Minimal"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-excluded-rd",
    "article": "Article 2",
    "description": "Excluded: Research & development - AI systems and models with the sole purpose of scientific research and development are excluded. For all other systems, research & development activities are likely excluded until your AI system is placed on the market or put into service. Systems and activities that are excluded are not subject to any obligations.",
    "applicableRoles": [
      "Provider",
      "Deployer"
    ],
    "riskCategory": [
      "Minimal"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-excluded-personal",
    "article": "Article 2",
    "description": "Excluded: Personal, non-professional activity - Obligations of deployers do not apply for a 'natural person' that deploys an AI system for purely personal, non-professional activities. This exclusion helps protect individual privacy and personal use cases from unnecessary regulatory burden.",
    "applicableRoles": [
      "Deployer"
    ],
    "riskCategory": [
      "Minimal"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-prohibited",
    "article": "Article 5",
    "description": "Prohibited systems - Your system may be prohibited under the EU AI Act if it performs any of the following functions: Subliminal techniques, manipulation, and deception; Exploiting vulnerabilities; Biometric categorisation; Social scoring; Predictive policing; Expanding facial recognition databases; Emotion recognition in the workplace or educational institutions (except for medical or safety reasons); Real-time remote biometrics.",
    "applicableRoles": [
      "Provider",
      "Deployer"
    ],
    "riskCategory": [
      "Prohibited"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-out-of-scope",
    "article": "Article 2",
    "description": "Out of scope - Your system is likely outside of the scope of the EU AI Act. This may be due to the system not meeting the definition of an AI system, not being placed on the market or put into service in the EU, or falling under specific exclusions outlined in Article 2.",
    "applicableRoles": [
      "Provider",
      "Deployer",
      "Distributor",
      "Importer",
      "AuthorizedRepresentative",
      "ProductManufacturer"
    ],
    "riskCategory": [
      "Minimal"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  },
  {
    "id": "obl-no-obligations",
    "article": "Article 95",
    "description": "No obligations - The EU AI Act likely imposes no legal obligations on your AI system. The European Commission may publish a voluntary code of conduct in future that you may be asked to comply with on a voluntary basis. This applies to systems that are in scope but do not meet the criteria for specific obligations.",
    "applicableRoles": [
      "Provider",
      "Deployer",
      "Distributor",
      "Importer",
      "AuthorizedRepresentative",
      "ProductManufacturer"
    ],
    "riskCategory": [
      "Minimal"
    ],
    "isGPAIApplicable": false,
    "hasSystemicRiskApplicable": false
  }
] 